---
title: "Mini-Project 5: Advantages and Drawbacks of Using p-values"
format: html
---

Questions: 1. Towards the end of Section 1, the authors say “As ‘statistical significance’ is used less, statistical thinking will be used more.” Elaborate on what you think the authors mean. Give some examples of what you think embodies “statistical thinking.”

I think the authors mean that as we move away from significant and not-significant p-values being strictly defined, there will be more room for exploration into what the p-value really represents. For projects that have p-values that are not far apart but one is significant and the other is not, they will have more in common despite results that are characterized as different. Statistical thinking takes into consideration values that are not significant according to p \< 0.05, but that clearly have some difference that has been calculated. There is more ways to interpret the p-value than just significance level, and statistical thinking looks not at the final result of the p-value, but the differences in the test.

2.  Section 2, third paragraph: The authors state “A label of statistical significance adds nothing to what is already conveyed by the value of p; in fact, this dichotomization of p-values makes matters worse.” Elaborate on what you think the authors mean.

I think the authors mean that making p-values have a strictly defined line of what is significant or not doesn’t add anything to how the p-value communicates the results of the tests. You could have 2 values that are 0.002 apart that give different levels of significance, which is not useful in the interpretation of the data. These p-values being interpreted differently is really just inaccurate, as they are very similar. Having a p-value 0.03 away from the level of significance is also not necessarily an indicator that there is no significant difference in the result. Having dichotomous p-values causes us to lose potentially interesting conclusions and findings because we define 2 similar values as strictly apart of one category.

3.  Section 2, end of first column: The authors state “For the integrity of scientific publishing and research dissemination, therefore, whether a p-value passes any arbitrary threshold should not be considered at all when deciding which results to present or highlight.” Do you agree or disagree? How should it be decided which results to present/highlight in scientific publishing?

I agree, using whether a test is significant to determine what results should be given publicity is not fair. Results should be decided based on the quality of the study and not if the results reached the significance level denoted by the p-value. Publishers/organizers should take into account the potential impact of the study and quality of the research over the final p-value result. If significant results are what causes studies to be given publicity, researchers could change the goals for their research from creating interesting and quality studies to finding ways to make statistical tests significant. This could develop into an issue, especially if researchers are tweaking their data/methods to appease the statistical whims of a p-value. The p-value and its significance should not be a deciding factor on what is done with research studies due to the arbitrary threshold it does or does not reach.

4.  Section 3, end of page 2: The authors state “The statistical community has not yet converged on a simple paradigm for the use of statistical inference in scientific research – and in fact it may never do so. A one-size-fits-all approach to statistical inference is an inappropriate expectation.” Do you agree or disagree? Explain.

I agree that there is more than one way to look for statistical significance in the results of a test. Different p-values can represent similar results, and looking at those values differently is not very fair. Different tests have different parameters, and comparing those levels of significance as the same isn’t necessarily an accurate measure of the differences between the data. Different research has different ways of defining differences, and each case has its own measure or level of success. Evaluating each case on its own allows us to assess the research as significant or not according to that specific instance. Comparing very different types of research using a single statistical value is not necessarily an accurate way to understand the relationships in the data.

5.  Section 3.2: The authors note that they are envisioning “a sort of ‘statistical thoughtfulness’.” What do you think “statistical thoughtfulness” means? What are some ways to demonstrate “statistical thoughtfulness” in an analysis?

Statistical thoughtfulness means including a variety of different statistical tests and viewing the data in different ways to fully consider how the data might be significant or not. The thoughtfulness is expanding on how the data is viewed beyond a simple p-value test, and finding more ways to test the significance of the findings. Some ways to demonstrate statistical thoughtfulness in an analysis is to use more statistical techniques like bootstrapping a difference in means to see any differences in the data. Looking at data in a few different ways is useful for gaining a deeper understanding of the research and whether or not the data can be further studied. Looking at data and finding a p-value is not the best way to really understand the results the data is producing, it is a simple look into what it has to offer.

6.  Section 3.2.4: A few of the authors of papers in this special issue argue that some of the terminology used in statistics, such as “significance” and “confidence” can be misleading, and they propose the use of “compatibility” instead. What you do you think they believe the problem is? Do you agree or disagree (that there is a problem and that changing the name will help)?

They believe that the terms “significance” and “confidence” are misleading and can create false trust in the results of the test. They think that seeing intervals and p-values creates a trust in the results that are not necessarily correct, and believe that compatibility better communicates the relationship between the null hypothesis and the significance of the data. Compatibility interval also better communicates the purpose of the confidence interval, and would be easier to understand for scientific researchers. I agree that there is a problem, but I think that changing the terminology would make people more confused as so many people use the current terminology. Transforming the words significance and confidence to compatibility would be difficult to do, especially with the widespread uses. They do not clear up enough confusion to be worth the effort.

7.  Find a quote or point that really strikes you (i.e., made you think). What is the quote (and tell me where to find it), and why does it stand out to you? My favorite quote comes at the bottom of page 5. All researchers, irrespective of their philosophy or practice, use expert judgment in developing models and interpreting results,” say Brownstein et al. “We must accept that there is subjectivity in every stage of scientific inquiry, but objectivity is nevertheless the funda- mental goal. Therefore, we should base judgments on evidence and careful reasoning, and seek wherever possible to eliminate potential sources of bias.”

This quote stood out to me as it connected ideas in scientific research to statistical analysis. It connects the scientific idea that you need to look at your results and research and make changes based on observations. It does however note the need to eliminate bias, and have some sort of evidence and careful reasoning as a basis for judgement. This connects to the idea of interpreting p-values based on circumstances and research, and not just whether they achieve a significant p-value.
